-----------  Configuration Arguments -----------
batch_size: 256
bert_config_path: ./bert_train/bert_config_beauty_64.json
candidate_path: ./bert_train/data/beauty.candidate
data_dir: ./bert_train/data/beauty-train.txt
data_name: beauty
epoch: 300
learning_rate: 0.0001
max_seq_len: 50
num_train_steps: 800000
test_set_dir: ./bert_train/data/beauty-test.txt
validation_steps: 1000
vocab_path: ./bert_train/data/beauty2.0.2.vocab
warmup_steps: 1000
weight_decay: 0.01
------------------------------------------------
Start to train Bert4rec
attention_probs_dropout_prob: 0.2
hidden_act: gelu
hidden_dropout_prob: 0.5
hidden_size: 64
initializer_range: 0.02
intermediate_size: 256
max_position_embeddings: 50
num_attention_heads: 2
num_hidden_layers: 2
type_vocab_size: 2
vocab_size: 54546
------------------------------------------------
W0924 00:48:50.879153  4052 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API V                                                ersion: 10.1
W0924 00:48:50.889564  4052 device_context.cc:422] device: 0, cuDNN Version: 7.6.
load candidate from :./bert_train/data/beauty.candidate
ac_beauty.py:131: DeprecationWarning:
Warning:
API "paddle.nn.functional.loss.softmax_with_cross_entropy" is deprecated since 2.0.0, and will be removed in future versions. Please use "paddl                                                e.nn.functional.cross_entropy" instead.
reason: Please notice that behavior of "paddle.nn.functional.softmax_with_cross_entropy" and "paddle.nn.functional.cross_entropy" is different.                                                
  logits=fc_out, label=mask_label, return_softmax=True)
epoch: 0, aver loss is: [10.147755]
epoch:    0, HR@10: 0.060634, NDCG@10: 0.028270, MRR: 0.039672
epoch: 1, aver loss is: [9.579391]
epoch:    1, HR@10: 0.130374, NDCG@10: 0.060072, MRR: 0.061295
epoch: 2, aver loss is: [9.228344]
epoch:    2, HR@10: 0.174886, NDCG@10: 0.081900, MRR: 0.076956
epoch: 3, aver loss is: [8.945813]
epoch:    3, HR@10: 0.204842, NDCG@10: 0.099452, MRR: 0.090302
epoch: 4, aver loss is: [8.733017]
epoch:    4, HR@10: 0.229946, NDCG@10: 0.115349, MRR: 0.102717
epoch: 5, aver loss is: [8.545521]
epoch:    5, HR@10: 0.251194, NDCG@10: 0.128915, MRR: 0.113309
epoch: 6, aver loss is: [8.369074]
epoch:    6, HR@10: 0.267367, NDCG@10: 0.139955, MRR: 0.122146
epoch: 7, aver loss is: [8.201591]
epoch:    7, HR@10: 0.279658, NDCG@10: 0.150064, MRR: 0.131136
epoch: 8, aver loss is: [8.048755]
epoch:    8, HR@10: 0.288664, NDCG@10: 0.158111, MRR: 0.138572
epoch: 9, aver loss is: [7.9108973]
epoch:    9, HR@10: 0.294909, NDCG@10: 0.163678, MRR: 0.143698
epoch: 10, aver loss is: [7.7876143]
epoch:   10, HR@10: 0.301776, NDCG@10: 0.169783, MRR: 0.149364
epoch: 11, aver loss is: [7.677249]
epoch:   11, HR@10: 0.305658, NDCG@10: 0.173193, MRR: 0.152531
epoch: 12, aver loss is: [7.578944]
epoch:   12, HR@10: 0.307325, NDCG@10: 0.175007, MRR: 0.154399
epoch: 13, aver loss is: [7.4895945]
epoch:   13, HR@10: 0.310908, NDCG@10: 0.177704, MRR: 0.156683
epoch: 14, aver loss is: [7.4091125]
epoch:   14, HR@10: 0.312102, NDCG@10: 0.179420, MRR: 0.158464
epoch: 15, aver loss is: [7.338613]
epoch:   15, HR@10: 0.311778, NDCG@10: 0.180003, MRR: 0.159329
epoch: 16, aver loss is: [7.2744894]
epoch:   16, HR@10: 0.312898, NDCG@10: 0.181352, MRR: 0.160771
epoch: 17, aver loss is: [7.218444]
epoch:   17, HR@10: 0.313047, NDCG@10: 0.182135, MRR: 0.161717
epoch: 18, aver loss is: [7.1674337]
epoch:   18, HR@10: 0.315013, NDCG@10: 0.183103, MRR: 0.162279
epoch: 19, aver loss is: [7.1184354]
epoch:   19, HR@10: 0.315411, NDCG@10: 0.183531, MRR: 0.162715
epoch: 20, aver loss is: [7.0740232]
epoch:   20, HR@10: 0.316133, NDCG@10: 0.184231, MRR: 0.163389
epoch: 21, aver loss is: [7.0356402]
epoch:   21, HR@10: 0.315386, NDCG@10: 0.183672, MRR: 0.162877
epoch: 22, aver loss is: [6.9981623]
epoch:   22, HR@10: 0.315784, NDCG@10: 0.183365, MRR: 0.162286
epoch: 23, aver loss is: [6.963977]
epoch:   23, HR@10: 0.315535, NDCG@10: 0.183409, MRR: 0.162398
epoch: 24, aver loss is: [6.931655]
epoch:   24, HR@10: 0.314092, NDCG@10: 0.182929, MRR: 0.162277
epoch: 25, aver loss is: [6.902967]
epoch:   25, HR@10: 0.314565, NDCG@10: 0.183798, MRR: 0.163190
epoch: 26, aver loss is: [6.876877]
epoch:   26, HR@10: 0.313645, NDCG@10: 0.183277, MRR: 0.162845
epoch: 27, aver loss is: [6.8513403]
epoch:   27, HR@10: 0.313868, NDCG@10: 0.183483, MRR: 0.163015
epoch: 28, aver loss is: [6.8276997]
epoch:   28, HR@10: 0.314217, NDCG@10: 0.183702, MRR: 0.163217
epoch: 29, aver loss is: [6.80198]
epoch:   29, HR@10: 0.315088, NDCG@10: 0.184514, MRR: 0.163911
epoch: 30, aver loss is: [6.7767496]
epoch:   30, HR@10: 0.315287, NDCG@10: 0.184384, MRR: 0.163648
epoch: 31, aver loss is: [6.7523503]
epoch:   31, HR@10: 0.314267, NDCG@10: 0.184640, MRR: 0.164356
epoch: 32, aver loss is: [6.7282205]
epoch:   32, HR@10: 0.315336, NDCG@10: 0.185370, MRR: 0.164942
epoch: 33, aver loss is: [6.703013]
epoch:   33, HR@10: 0.316232, NDCG@10: 0.185520, MRR: 0.164816
epoch: 34, aver loss is: [6.679235]
epoch:   34, HR@10: 0.316232, NDCG@10: 0.185736, MRR: 0.165089
epoch: 35, aver loss is: [6.6561794]
epoch:   35, HR@10: 0.316705, NDCG@10: 0.186363, MRR: 0.165731
epoch: 36, aver loss is: [6.6351347]
epoch:   36, HR@10: 0.316356, NDCG@10: 0.186741, MRR: 0.166282
epoch: 37, aver loss is: [6.6112995]
epoch:   37, HR@10: 0.316108, NDCG@10: 0.186608, MRR: 0.166214
epoch: 38, aver loss is: [6.5922813]
epoch:   38, HR@10: 0.316207, NDCG@10: 0.187040, MRR: 0.166705
epoch: 39, aver loss is: [6.5720024]
epoch:   39, HR@10: 0.316207, NDCG@10: 0.187387, MRR: 0.167146
epoch: 40, aver loss is: [6.5531797]
epoch:   40, HR@10: 0.314789, NDCG@10: 0.186410, MRR: 0.166274
epoch: 41, aver loss is: [6.5335283]
epoch:   41, HR@10: 0.315262, NDCG@10: 0.186896, MRR: 0.166679
epoch: 42, aver loss is: [6.5181894]
epoch:   42, HR@10: 0.315013, NDCG@10: 0.187054, MRR: 0.166968
epoch: 43, aver loss is: [6.500649]
epoch:   43, HR@10: 0.314416, NDCG@10: 0.186833, MRR: 0.166854
epoch: 44, aver loss is: [6.4843607]
epoch:   44, HR@10: 0.314665, NDCG@10: 0.186779, MRR: 0.166613
epoch: 45, aver loss is: [6.468182]
epoch:   45, HR@10: 0.313570, NDCG@10: 0.186576, MRR: 0.166720
epoch: 46, aver loss is: [6.452643]
epoch:   46, HR@10: 0.313346, NDCG@10: 0.186304, MRR: 0.166407
epoch: 47, aver loss is: [6.4385357]
epoch:   47, HR@10: 0.312400, NDCG@10: 0.185860, MRR: 0.166087
epoch: 48, aver loss is: [6.425352]
epoch:   48, HR@10: 0.313097, NDCG@10: 0.186422, MRR: 0.166590
epoch: 49, aver loss is: [6.410291]
epoch:   49, HR@10: 0.312276, NDCG@10: 0.185988, MRR: 0.166245
epoch: 50, aver loss is: [6.399139]
epoch:   50, HR@10: 0.314192, NDCG@10: 0.187255, MRR: 0.167230
epoch: 51, aver loss is: [6.3866367]
epoch:   51, HR@10: 0.313868, NDCG@10: 0.187085, MRR: 0.167106
epoch: 52, aver loss is: [6.373531]
epoch:   52, HR@10: 0.314714, NDCG@10: 0.188047, MRR: 0.168072
epoch: 53, aver loss is: [6.360357]
epoch:   53, HR@10: 0.315013, NDCG@10: 0.188591, MRR: 0.168630
epoch: 54, aver loss is: [6.3475485]
epoch:   54, HR@10: 0.314640, NDCG@10: 0.188065, MRR: 0.168069
epoch: 55, aver loss is: [6.333163]
epoch:   55, HR@10: 0.315934, NDCG@10: 0.189396, MRR: 0.169412
epoch: 56, aver loss is: [6.320053]
epoch:   56, HR@10: 0.314689, NDCG@10: 0.188836, MRR: 0.169104
epoch: 57, aver loss is: [6.3055677]
epoch:   57, HR@10: 0.314267, NDCG@10: 0.188265, MRR: 0.168499
epoch: 58, aver loss is: [6.2933]
epoch:   58, HR@10: 0.312873, NDCG@10: 0.187539, MRR: 0.167970
epoch: 59, aver loss is: [6.2800074]
epoch:   59, HR@10: 0.314018, NDCG@10: 0.188194, MRR: 0.168443
epoch: 60, aver loss is: [6.26458]
epoch:   60, HR@10: 0.312400, NDCG@10: 0.187781, MRR: 0.168476
epoch: 61, aver loss is: [6.251914]
epoch:   61, HR@10: 0.312152, NDCG@10: 0.187959, MRR: 0.168773
epoch: 62, aver loss is: [6.236579]
epoch:   62, HR@10: 0.312550, NDCG@10: 0.187808, MRR: 0.168420
epoch: 63, aver loss is: [6.2251954]
epoch:   63, HR@10: 0.313172, NDCG@10: 0.187906, MRR: 0.168307
epoch: 64, aver loss is: [6.212028]
epoch:   64, HR@10: 0.312052, NDCG@10: 0.187225, MRR: 0.167824
epoch: 65, aver loss is: [6.2024755]
epoch:   65, HR@10: 0.312674, NDCG@10: 0.187517, MRR: 0.167952
epoch: 66, aver loss is: [6.1904116]
epoch:   66, HR@10: 0.312699, NDCG@10: 0.187866, MRR: 0.168409
epoch: 67, aver loss is: [6.1819296]
epoch:   67, HR@10: 0.310485, NDCG@10: 0.187103, MRR: 0.168159
epoch: 68, aver loss is: [6.173538]
epoch:   68, HR@10: 0.311505, NDCG@10: 0.186855, MRR: 0.167508
epoch: 69, aver loss is: [6.1647396]
epoch:   69, HR@10: 0.311579, NDCG@10: 0.187429, MRR: 0.168210
epoch: 70, aver loss is: [6.162481]
epoch:   70, HR@10: 0.310659, NDCG@10: 0.187184, MRR: 0.168185
epoch: 71, aver loss is: [6.154367]
epoch:   71, HR@10: 0.310609, NDCG@10: 0.186956, MRR: 0.167968
epoch: 72, aver loss is: [6.1493]
epoch:   72, HR@10: 0.310460, NDCG@10: 0.186479, MRR: 0.167375
epoch: 73, aver loss is: [6.1421366]
epoch:   73, HR@10: 0.311604, NDCG@10: 0.187699, MRR: 0.168560
epoch: 74, aver loss is: [6.1336927]
epoch:   74, HR@10: 0.312052, NDCG@10: 0.187731, MRR: 0.168511
epoch: 75, aver loss is: [6.1262355]
epoch:   75, HR@10: 0.312674, NDCG@10: 0.188213, MRR: 0.168898
epoch: 76, aver loss is: [6.116277]
epoch:   76, HR@10: 0.311729, NDCG@10: 0.187469, MRR: 0.168241
epoch: 77, aver loss is: [6.106788]
epoch:   77, HR@10: 0.311430, NDCG@10: 0.187934, MRR: 0.168926
epoch: 78, aver loss is: [6.096748]
epoch:   78, HR@10: 0.312351, NDCG@10: 0.188534, MRR: 0.169402
epoch: 79, aver loss is: [6.0873184]
epoch:   79, HR@10: 0.311455, NDCG@10: 0.187773, MRR: 0.168615
epoch: 80, aver loss is: [6.0778184]
epoch:   80, HR@10: 0.308892, NDCG@10: 0.186704, MRR: 0.168117
epoch: 81, aver loss is: [6.0687113]
epoch:   81, HR@10: 0.308843, NDCG@10: 0.186592, MRR: 0.168012
epoch: 82, aver loss is: [6.063019]
epoch:   82, HR@10: 0.307449, NDCG@10: 0.186566, MRR: 0.168405
epoch: 83, aver loss is: [6.0564623]
epoch:   83, HR@10: 0.308071, NDCG@10: 0.186259, MRR: 0.167711
epoch: 84, aver loss is: [6.0500774]
epoch:   84, HR@10: 0.307350, NDCG@10: 0.185655, MRR: 0.167194
epoch: 85, aver loss is: [6.044439]
epoch:   85, HR@10: 0.306827, NDCG@10: 0.185876, MRR: 0.167654
epoch: 86, aver loss is: [6.0392013]
epoch:   86, HR@10: 0.306529, NDCG@10: 0.185745, MRR: 0.167586
epoch: 87, aver loss is: [6.0290275]
epoch:   87, HR@10: 0.307673, NDCG@10: 0.186201, MRR: 0.167804
epoch: 88, aver loss is: [6.020669]
epoch:   88, HR@10: 0.307001, NDCG@10: 0.185559, MRR: 0.167202
epoch: 89, aver loss is: [6.0135636]
epoch:   89, HR@10: 0.307847, NDCG@10: 0.186524, MRR: 0.168192
epoch: 90, aver loss is: [6.006114]
epoch:   90, HR@10: 0.309365, NDCG@10: 0.187451, MRR: 0.168875
epoch: 91, aver loss is: [5.997813]
epoch:   91, HR@10: 0.309241, NDCG@10: 0.187624, MRR: 0.169158
epoch: 92, aver loss is: [5.9908495]
epoch:   92, HR@10: 0.310286, NDCG@10: 0.187855, MRR: 0.169115
epoch: 93, aver loss is: [5.982672]
epoch:   93, HR@10: 0.309713, NDCG@10: 0.187879, MRR: 0.169305
epoch: 94, aver loss is: [5.9756627]
epoch:   94, HR@10: 0.311132, NDCG@10: 0.188628, MRR: 0.169799
epoch: 95, aver loss is: [5.9665446]
epoch:   95, HR@10: 0.310385, NDCG@10: 0.187933, MRR: 0.169148
epoch: 96, aver loss is: [5.9580493]
epoch:   96, HR@10: 0.310410, NDCG@10: 0.187803, MRR: 0.168952
epoch: 97, aver loss is: [5.9503627]
epoch:   97, HR@10: 0.309838, NDCG@10: 0.187952, MRR: 0.169354
epoch: 98, aver loss is: [5.94]
epoch:   98, HR@10: 0.308519, NDCG@10: 0.187582, MRR: 0.169317
epoch: 99, aver loss is: [5.932603]
epoch:   99, HR@10: 0.309564, NDCG@10: 0.188206, MRR: 0.169800
epoch: 100, aver loss is: [5.923897]
epoch:  100, HR@10: 0.309216, NDCG@10: 0.187461, MRR: 0.168921
epoch: 101, aver loss is: [5.91771]
epoch:  101, HR@10: 0.308569, NDCG@10: 0.187737, MRR: 0.169478
epoch: 102, aver loss is: [5.908505]
epoch:  102, HR@10: 0.308420, NDCG@10: 0.187354, MRR: 0.169003
epoch: 103, aver loss is: [5.9017644]
epoch:  103, HR@10: 0.308146, NDCG@10: 0.187303, MRR: 0.169054
epoch: 104, aver loss is: [5.896985]
epoch:  104, HR@10: 0.309888, NDCG@10: 0.188445, MRR: 0.169928
epoch: 105, aver loss is: [5.8917713]
epoch:  105, HR@10: 0.309465, NDCG@10: 0.187878, MRR: 0.169321
epoch: 106, aver loss is: [5.8868318]
epoch:  106, HR@10: 0.309465, NDCG@10: 0.187934, MRR: 0.169375
epoch: 107, aver loss is: [5.8815284]
epoch:  107, HR@10: 0.308444, NDCG@10: 0.187560, MRR: 0.169269
epoch: 108, aver loss is: [5.8783827]
epoch:  108, HR@10: 0.309141, NDCG@10: 0.187701, MRR: 0.169169
epoch: 109, aver loss is: [5.874594]
epoch:  109, HR@10: 0.308718, NDCG@10: 0.187120, MRR: 0.168563
epoch: 110, aver loss is: [5.871691]
epoch:  110, HR@10: 0.309141, NDCG@10: 0.187713, MRR: 0.169278
epoch: 111, aver loss is: [5.8719964]
epoch:  111, HR@10: 0.308668, NDCG@10: 0.187377, MRR: 0.168984
epoch: 112, aver loss is: [5.8703732]
epoch:  112, HR@10: 0.308644, NDCG@10: 0.187793, MRR: 0.169538
epoch: 113, aver loss is: [5.8716116]
epoch:  113, HR@10: 0.310286, NDCG@10: 0.187952, MRR: 0.169176
epoch: 114, aver loss is: [5.8736877]
epoch:  114, HR@10: 0.313147, NDCG@10: 0.189658, MRR: 0.170450
epoch: 115, aver loss is: [5.875052]
epoch:  115, HR@10: 0.311679, NDCG@10: 0.189533, MRR: 0.170761
epoch: 116, aver loss is: [5.871748]
epoch:  116, HR@10: 0.311231, NDCG@10: 0.189263, MRR: 0.170560
epoch: 117, aver loss is: [5.868465]
epoch:  117, HR@10: 0.313172, NDCG@10: 0.190444, MRR: 0.171416
epoch: 118, aver loss is: [5.862249]
epoch:  118, HR@10: 0.312649, NDCG@10: 0.190426, MRR: 0.171542
epoch: 119, aver loss is: [5.856444]
epoch:  119, HR@10: 0.313595, NDCG@10: 0.191302, MRR: 0.172359
epoch: 120, aver loss is: [5.851245]
epoch:  120, HR@10: 0.313371, NDCG@10: 0.191132, MRR: 0.172219
epoch: 121, aver loss is: [5.8457284]
epoch:  121, HR@10: 0.313222, NDCG@10: 0.191270, MRR: 0.172435
epoch: 122, aver loss is: [5.8428397]
epoch:  122, HR@10: 0.311928, NDCG@10: 0.190125, MRR: 0.171345
epoch: 123, aver loss is: [5.837084]
epoch:  123, HR@10: 0.312923, NDCG@10: 0.191043, MRR: 0.172186
epoch: 124, aver loss is: [5.832323]
epoch:  124, HR@10: 0.311928, NDCG@10: 0.191069, MRR: 0.172577
epoch: 125, aver loss is: [5.828357]
epoch:  125, HR@10: 0.312998, NDCG@10: 0.191088, MRR: 0.172233
epoch: 126, aver loss is: [5.824623]
epoch:  126, HR@10: 0.311853, NDCG@10: 0.190257, MRR: 0.171497
epoch: 127, aver loss is: [5.8205924]
epoch:  127, HR@10: 0.311480, NDCG@10: 0.190133, MRR: 0.171454
epoch: 128, aver loss is: [5.8179393]
epoch:  128, HR@10: 0.311579, NDCG@10: 0.190471, MRR: 0.171832
epoch: 129, aver loss is: [5.816147]
epoch:  129, HR@10: 0.312102, NDCG@10: 0.190961, MRR: 0.172312
epoch: 130, aver loss is: [5.8127284]
epoch:  130, HR@10: 0.311754, NDCG@10: 0.190151, MRR: 0.171322
epoch: 131, aver loss is: [5.8099346]
epoch:  131, HR@10: 0.311505, NDCG@10: 0.189608, MRR: 0.170738
epoch: 132, aver loss is: [5.8061657]
epoch:  132, HR@10: 0.310286, NDCG@10: 0.189353, MRR: 0.170828
epoch: 133, aver loss is: [5.8043075]
epoch:  133, HR@10: 0.310858, NDCG@10: 0.190021, MRR: 0.171508
epoch: 134, aver loss is: [5.8016148]
epoch:  134, HR@10: 0.309713, NDCG@10: 0.189441, MRR: 0.171189
epoch: 135, aver loss is: [5.7994957]
epoch:  135, HR@10: 0.310758, NDCG@10: 0.189666, MRR: 0.171082
epoch: 136, aver loss is: [5.795754]
epoch:  136, HR@10: 0.311082, NDCG@10: 0.189453, MRR: 0.170669
epoch: 137, aver loss is: [5.792514]
epoch:  137, HR@10: 0.311828, NDCG@10: 0.189933, MRR: 0.171017
epoch: 138, aver loss is: [5.7883306]
epoch:  138, HR@10: 0.311032, NDCG@10: 0.189402, MRR: 0.170638
epoch: 139, aver loss is: [5.7831206]
epoch:  139, HR@10: 0.310957, NDCG@10: 0.189251, MRR: 0.170451
epoch: 140, aver loss is: [5.780411]
epoch:  140, HR@10: 0.311480, NDCG@10: 0.190277, MRR: 0.171627
epoch: 141, aver loss is: [5.778404]
epoch:  141, HR@10: 0.312525, NDCG@10: 0.190890, MRR: 0.172095
epoch: 142, aver loss is: [5.772742]
epoch:  142, HR@10: 0.311754, NDCG@10: 0.190283, MRR: 0.171580
epoch: 143, aver loss is: [5.7693396]
epoch:  143, HR@10: 0.312550, NDCG@10: 0.190739, MRR: 0.171876
epoch: 144, aver loss is: [5.7682457]
epoch:  144, HR@10: 0.312649, NDCG@10: 0.190921, MRR: 0.172074
epoch: 145, aver loss is: [5.7642226]
epoch:  145, HR@10: 0.311405, NDCG@10: 0.190570, MRR: 0.172101
epoch: 146, aver loss is: [5.7607656]
epoch:  146, HR@10: 0.312077, NDCG@10: 0.190530, MRR: 0.171787
epoch: 147, aver loss is: [5.7566323]
epoch:  147, HR@10: 0.312525, NDCG@10: 0.190555, MRR: 0.171640
epoch: 148, aver loss is: [5.753117]
epoch:  148, HR@10: 0.312450, NDCG@10: 0.191124, MRR: 0.172481
epoch: 149, aver loss is: [5.749717]
epoch:  149, HR@10: 0.312052, NDCG@10: 0.190450, MRR: 0.171745
epoch: 150, aver loss is: [5.7463994]
epoch:  150, HR@10: 0.312102, NDCG@10: 0.190890, MRR: 0.172275
epoch: 151, aver loss is: [5.7423625]
epoch:  151, HR@10: 0.312177, NDCG@10: 0.191012, MRR: 0.172416
epoch: 152, aver loss is: [5.739655]
epoch:  152, HR@10: 0.312301, NDCG@10: 0.190869, MRR: 0.172197
